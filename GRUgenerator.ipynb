{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46a262f3-760a-4239-a12f-0a006caee913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab274d5e-4db9-490d-ab01-125050c6d2d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4601\n",
      "Shape of X: (4601, 49, 52)\n",
      "Shape of y: (4601, 49, 52)\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_6 (GRU)                 (None, 49, 256)           238080    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 49, 52)            13364     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 251444 (982.20 KB)\n",
      "Trainable params: 251444 (982.20 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 2s 20ms/step - loss: 3.3395 - accuracy: 0.2400\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 2.7028 - accuracy: 0.2887\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 2.3088 - accuracy: 0.4801\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 1.7329 - accuracy: 0.5872\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 1.2118 - accuracy: 0.6831\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.8753 - accuracy: 0.7680\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.6789 - accuracy: 0.8100\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.5664 - accuracy: 0.8238\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.4976 - accuracy: 0.8322\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.4507 - accuracy: 0.8371\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.4170 - accuracy: 0.8434\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3929 - accuracy: 0.8482\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3729 - accuracy: 0.8503\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3603 - accuracy: 0.8521\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.3491 - accuracy: 0.8538\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3387 - accuracy: 0.8551\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.3309 - accuracy: 0.8562\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.3264 - accuracy: 0.8564\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.3214 - accuracy: 0.8570\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3176 - accuracy: 0.8577\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3126 - accuracy: 0.8583\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3102 - accuracy: 0.8586\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.3076 - accuracy: 0.8590\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.3054 - accuracy: 0.8585\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3034 - accuracy: 0.8593\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3016 - accuracy: 0.8596\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3005 - accuracy: 0.8590\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.2983 - accuracy: 0.8600\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2965 - accuracy: 0.8600\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2969 - accuracy: 0.8598\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.2953 - accuracy: 0.8607\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2935 - accuracy: 0.8607\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2928 - accuracy: 0.8603\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.2918 - accuracy: 0.8604\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2925 - accuracy: 0.8609\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2905 - accuracy: 0.8612\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2894 - accuracy: 0.8612\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2886 - accuracy: 0.8612\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2887 - accuracy: 0.8613\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2880 - accuracy: 0.8613\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2865 - accuracy: 0.8622\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.2856 - accuracy: 0.8625\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2858 - accuracy: 0.8631\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.2852 - accuracy: 0.8626\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2841 - accuracy: 0.8628\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2849 - accuracy: 0.8633\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2833 - accuracy: 0.8635\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2816 - accuracy: 0.8644\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2802 - accuracy: 0.8642\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2804 - accuracy: 0.8644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f061c108790>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# 加载数据\n",
    "df = pd.read_csv('jianceresults20000-40.csv')  # 修改为实际的文件路径\n",
    "df = df[df['Resultnaxsi'] == 403]\n",
    "payloads = df['Payload'].values\n",
    "print(len(payloads))\n",
    "\n",
    "# 添加开始和结束标识符\n",
    "start_token = \"<start>\"\n",
    "end_token = \"<end>\"\n",
    "\n",
    "# 提取所有唯一的字符，并添加开始和结束标识符\n",
    "chars = set(''.join(payloads))  # 所有Payload中出现的字符\n",
    "chars = sorted(list(chars))\n",
    "chars = [start_token, end_token] + chars  # 在字符集前加上 <start> 和 <end>\n",
    "\n",
    "# 创建字符到索引的映射\n",
    "char_to_index = {char: index for index, char in enumerate(chars)}\n",
    "index_to_char = {index: char for index, char in enumerate(chars)}\n",
    "\n",
    "# 进行One-hot编码\n",
    "def one_hot_encode(payload):\n",
    "    return [char_to_index[char] for char in payload]\n",
    "\n",
    "# 将整数索引转换为One-hot编码\n",
    "def integer_to_one_hot(encoded_payload):\n",
    "    one_hot_encoded = np.zeros((len(encoded_payload), len(chars)))\n",
    "    for i, index in enumerate(encoded_payload):\n",
    "        one_hot_encoded[i, index] = 1\n",
    "    return one_hot_encoded\n",
    "\n",
    "# 训练数据生成\n",
    "X, y = [], []\n",
    "sequence_length = 50 # 每个输入序列的长度\n",
    "\n",
    "for payload in payloads:\n",
    "    # 添加 <start> 和 <end> 标识符\n",
    "    payload_with_tokens = payload\n",
    "    \n",
    "    payload_encoded = [0]+one_hot_encode(payload_with_tokens)\n",
    "    \n",
    "    # 如果长度小于30，使用0填充至30；如果超过30，截断为30\n",
    "    if len(payload_encoded) < sequence_length:\n",
    "        # 填充不足的部分为0\n",
    "        padding_length = sequence_length - len(payload_encoded)\n",
    "        payload_encoded += [1] * padding_length  # 用全0填充\n",
    "    elif len(payload_encoded) > sequence_length:\n",
    "        # 截断多余部分\n",
    "        payload_encoded = payload_encoded[:sequence_length]\n",
    "\n",
    "    # 生成X和y\n",
    "    X.append(payload_encoded[:-1])  # 输入序列是前29个字符\n",
    "    y.append(payload_encoded[1:])  # 标签是后29个字符\n",
    "\n",
    "# 转换为NumPy数组并进行One-hot编码\n",
    "X = np.array([integer_to_one_hot(seq) for seq in X])\n",
    "y = np.array([integer_to_one_hot(seq) for seq in y])\n",
    "\n",
    "# 打印X和y的形状以确认数据是否正确生成\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# 构建GRU模型\n",
    "model = Sequential()\n",
    "model.add(GRU(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))  # 256个GRU单元\n",
    "model.add(Dense(len(chars), activation='softmax'))  # 输出层，大小为字符集的大小，softmax用于分类\n",
    "\n",
    "# 编译模型\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# 打印模型摘要\n",
    "model.summary()\n",
    "\n",
    "# 训练GRU模型\n",
    "model.fit(X, y, epochs=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7187a552-64f5-4714-a3dd-3d61f2055591",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bacdac-879e-47cd-b70a-966e179cb19e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dec95446-c978-4a4e-b9ab-45174c70c4f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32d81cdd-df2e-4e41-bd9a-4ca100b57a7e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start>',\n",
       " '<end>',\n",
       " '!',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '@',\n",
       " 'C',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'i',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'x',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff74fb48-705e-4509-ae66-9b3b8d09028d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Payload:\n",
      "+&&%0bnot%7e0%0bor%270\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample(predictions, temperature=1.0):\n",
    "    # 对概率进行温度调整，避免过于确定性或者过于随机的选择\n",
    "    predictions = np.asarray(predictions).astype('float64')\n",
    "    predictions = np.log(predictions + 1e-8) / temperature  # 进行log转换并除以温度\n",
    "    predictions = np.exp(predictions)  # 还原为概率分布\n",
    "    predictions = predictions / np.sum(predictions)  # 归一化为概率分布\n",
    "    \n",
    "    # 使用调整后的概率进行采样\n",
    "    return np.random.choice(len(predictions), p=predictions)\n",
    "\n",
    "def generate_payload_with_sampling(model, start_token=\"<start>\", end_token=\"<end>\", sequence_length=100, max_length=200, temperature=1.0):\n",
    "    # 初始化生成的payload，包含开始标识符\n",
    "    generated_payload = [start_token]\n",
    "    \n",
    "    # 将生成的payload转为One-hot编码\n",
    "    current_sequence = [char_to_index[char] for char in generated_payload]  # 初始化为[<start>]\n",
    "    # 填充序列到 sequence_length - 1 (99) 长度\n",
    "    while len(current_sequence) < sequence_length - 1:\n",
    "        current_sequence.append(char_to_index['1'])  # 使用空格或某个默认字符进行填充\n",
    "    \n",
    "    current_sequence = np.array(current_sequence).reshape(1, -1)  # 添加批量维度, 现在是(1, 99)\n",
    "    \n",
    "    # 将current_sequence转换为One-hot编码\n",
    "    current_sequence_one_hot = np.zeros((1, len(current_sequence[0]), len(chars)))\n",
    "    for i, index in enumerate(current_sequence[0]):\n",
    "        current_sequence_one_hot[0, i, index] = 1  # 当前序列的One-hot编码\n",
    "    \n",
    "    # 开始生成字符，直到达到最大长度或遇到end_token\n",
    "    while len(generated_payload) < max_length:\n",
    "        # 进行预测，输出的概率分布\n",
    "        predictions = model.predict(current_sequence_one_hot, verbose=0)\n",
    "        \n",
    "        # 从预测结果中选取通过温度调节后的字符\n",
    "        predicted_index = sample(predictions[0, -1], temperature)  # 进行采样\n",
    "        predicted_char = index_to_char[predicted_index]\n",
    "        \n",
    "        # 如果预测的是结束标识符，则停止生成\n",
    "        if predicted_char == end_token:\n",
    "            break\n",
    "        \n",
    "        # 将预测的字符添加到生成的payload中\n",
    "        generated_payload.append(predicted_char)\n",
    "        \n",
    "        # 更新当前序列，移除最左边的字符，加入新预测的字符\n",
    "        current_sequence = np.append(current_sequence[:, 1:], [[predicted_index]], axis=1)\n",
    "        \n",
    "        # 更新current_sequence的One-hot编码\n",
    "        current_sequence_one_hot = np.zeros((1, len(current_sequence[0]), len(chars)))\n",
    "        for i, index in enumerate(current_sequence[0]):\n",
    "            current_sequence_one_hot[0, i, index] = 1  # 更新为新的One-hot编码\n",
    "    \n",
    "    return ''.join(generated_payload[1:])  # 忽略开始标识符返回结果\n",
    "\n",
    "# 使用训练好的模型生成payload\n",
    "generated_payload = generate_payload_with_sampling(model, sequence_length=sequence_length ,temperature=0.7)  # 调整温度值来调节生成的随机性\n",
    "print(\"Generated Payload:\")\n",
    "print(generated_payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff322190-6c2e-4221-9984-0e13ac208dec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f348c-614f-43be-8be7-4a38d144a75b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 generations 列表已经包含生成的负载\n",
    "generations = []\n",
    "\n",
    "for i in range(4000):\n",
    "    generat = generate_payload_with_sampling(model, sequence_length=sequence_length, temperature=1) \n",
    "    print(generat)\n",
    "    generations.append(generat)\n",
    "\n",
    "# 将生成的负载保存到DataFrame\n",
    "df_generations = pd.DataFrame(generations, columns=[\"Generated_Payload\"])\n",
    "\n",
    "# 将DataFrame保存到CSV文件\n",
    "output_csv = 'generated_payloads.csv'  # 自定义保存的文件名\n",
    "df_generations.to_csv(output_csv, index=False)\n",
    "\n",
    "# 输出保存的结果\n",
    "print(f\"Generated payloads saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b62dab-198f-418a-8319-636b126fe0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f65cc029-6f0e-48f8-a0f9-33bf49104fac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length of the elements in the 'Payload' column is: 81\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_max_payload_length(csv_file):\n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # 计算 Payload 列中每个元素的长度\n",
    "    df['Payload_length'] = df['Payload'].apply(len)\n",
    "    \n",
    "    # 获取最大长度\n",
    "    max_length = df['Payload_length'].max()\n",
    "\n",
    "    # 输出最大长度\n",
    "    print(f\"The maximum length of the elements in the 'Payload' column is: {max_length}\")\n",
    "    return max_length\n",
    "\n",
    "# 运行计算最大长度的函数\n",
    "csv_file = 'output40.csv'  # 请确保文件路径正确\n",
    "max_length = find_max_payload_length(csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b1b526-6d7b-44a0-be2b-2f2e43e10338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
